
%h1 Grand Challenges


%div{class: 'panel-group', id: 'accordion'}
	%div{class: 'panel panel-primary'}
		%div{class: 'panel-heading'}
			%h4{class: 'panel-title'}
				%a{'data-toggle': 'collapse', 'data-parent': '#accordion', href: '#gc-pcc'}
					Point Cloud Coding
				%span{class: 'glyphicon glyphicon-link pull-right clickable-workshop-link', ldata: 'gc-pcc'}
		%div{id: 'gc-pcc', class: 'panel-collapse collapse'}
			%div{class: 'panel-body'}
				%h4{class: 'specsess-heading'} Description
				%p With the significant growth of 3D sensing technologies point clouds have become a viable solution, since they provide practical ways for capture, storage, delivery and rendering in augmented reality, mixed reality, virtual reality, medical imaging and 3D printing applications, among others. There is a need for an interchange and delivery format allowing an efficient point cloud compression with minimal or no impact on their quality. This challenge solicits contributions for this purpose. Moreover, new evaluation methodologies are sought. Furthermore, additional publicly accessible point cloud content along with evidence for compression efficiency as well as other attractive features are also accepted.
				/ %h4{class: 'specsess-heading'} Important Dates
				/ %ul
				/ 	%li January 15, 2018: Grand Challenge proponents’ expression of interest
				/ 	%li February 15, 2018: Grand Challenge proponents’ submission
				/ 	%li March 1, 2018: Grand Challenge proponents’ optional paper submission
				/ 	%li March 15, 2018: Grand Challenge results paper submission
				/ 	%li March 31, 2018: Grand Challenge acceptance notification
				/ 	%li April 13, 2018: Grand Challenge camera-ready paper submission
				%h4{class: 'specsess-heading'} Website
				%a{href: 'https://mmspg.epfl.ch/ICME2018GrandChallenge'} https://mmspg.epfl.ch/ICME2018GrandChallenge
				%h4{class: 'specsess-heading'} Organizers
				= render 'chairs', target: :gc_pcc

	%div{class: 'panel panel-primary'}
		%div{class: 'panel-heading'}
			%h4{class: 'panel-title'}
				%a{'data-toggle': 'collapse', 'data-parent': '#accordion', href: '#gc-hfr'}
					Heterogeneous Face Recognition: Polarimetric Thermal-to-Visible Matching
				%span{class: 'glyphicon glyphicon-link pull-right clickable-workshop-link', ldata: 'gc-hfr'}
		%div{id: 'gc-hfr', class: 'panel-collapse collapse'}
			%div{class: 'panel-body'}
				%h4{class: 'specsess-heading'} Description
				%p This grand challenge is focused on heterogeneous face recognition, specifically on polarimetric thermal-to-visible matching. The motivation behind this challenge is the development of a nighttime face recognition capability for homeland security and defense. The challenge organizers will provide a polarimetric thermal and visible face database for algorithm development. Participants will be asked to provide heterogeneous face recognition algorithms in the form of executables, that take a pair of images (an aligned polarimetric thermal face image and an aligned visible face image) as input and provide a similarity score as output. Algorithms will be ranked by their face verification performance using ROCcurves.
				/ %h4{class: 'specsess-heading'} Important Dates
				/ %ul
				/ 	%li February 7, 2018: Executable files submitted to coordinators
				/ 	%li February 28, 2018: Winner announced
				/ 	%li March 15, 2018: (Optional) Winner paper submission
				/ 	%li March 31, 2018: Paper acceptance notification
				/ 	%li April 13, 2018: Camera-ready paper submission
				%h4{class: 'specsess-heading'} Website
				TBA
				%h4{class: 'specsess-heading'} Organizers
				= render 'chairs', target: :gc_hfr

	%div{class: 'panel panel-primary'}
		%div{class: 'panel-heading'}
			%h4{class: 'panel-title'}
				%a{'data-toggle': 'collapse', 'data-parent': '#accordion', href: '#gc-abr'}
					ABR Bandwidth Estimation For HTTP Chunked Transfer Coding
				%span{class: 'glyphicon glyphicon-link pull-right clickable-workshop-link', ldata: 'gc-abr'}
		%div{id: 'gc-abr', class: 'panel-collapse collapse'}
			%div{class: 'panel-body'}
				%h4{class: 'specsess-heading'} Description
				%p 
					One of the most successful efforts to reduce the latency of HTTP streaming is to utilize the HTTP chunked transfer coding, which enables a video segment to be generated and transmitted concurrently. For more technical details, please read Twitter’s recent technical blog 
					%a{href: 'https://medium.com/@periscopecode/introducing-lhls-media-streaming- eb6212948bef'} Introducing LHLS Media Streaming

				%p However, compared with segment-based HTTP download, chunked transfer coding makes the bandwidth estimation a lot harder for any ABR playback algorithm. This Grand Challenge is to call for signal-processing/machine-learning algorithms that can effectively estimate download bandwidth based on the noisy samples of chunked-based download throughput.
				%h4{class: 'specsess-heading'} Important Dates
				/ %ul 
				/ 	%li February 15, 2018: Results due
				/ 	%li February 25, 2018: Winner selected
				/ 	%li March 1, 2018: Winner paper submission due
				/ 	%li March 31, 2018: Paper acceptance notified
				/ 	%li April 13, 2018: Camera-ready paper submission due
				%h4{class: 'specsess-heading'} Website
				TBA
				%h4{class: 'specsess-heading'} Organizers
				= render 'chairs', target: :gc_abr

	%div{class: 'panel panel-primary'}
		%div{class: 'panel-heading'}
			%h4{class: 'panel-title'}
				%a{'data-toggle': 'collapse', 'data-parent': '#accordion', href: '#gc-dlfr'}
					Densely-sampled Light Field Reconstruction
				%span{class: 'glyphicon glyphicon-link pull-right clickable-workshop-link', ldata: 'gc-dlfr'}
		%div{id: 'gc-dlfr', class: 'panel-collapse collapse'}
			%div{class: 'panel-body'}
				%h4{class: 'specsess-heading'} Description
				%p Densely-sampled light field (DSLF) is a discrete representation of the 4D approximation of the plenoptic function, where multi-perspective camera views are arranged in such a way that the disparities between adjacent views are less than one pixel. DSLF is an attractive representation of scene visual content, particularly for applications which require ray interpolation and view synthesis. However, direct DSLF capture of real-world scenes is not practical. In this Grand Challenge, proponents are invited to develop and implement algorithms for DSLF reconstruction from decimated-parallax imagery, i.e. from a given sparse set of camera images.
				%h4{class: 'specsess-heading'} Important Dates
				/ %ul
				/ 	%li December 15, 2017: Grand Challenge web site operational; release of Development Datasets and scripts for calculating the quality metric
				/ 	%li March 16, 2018: Submission of binaries to organizers
				/ 	%li March 23, 2018: Grand Challenge papers submission
				/ 	%li March 26, 2018: Feedback to proponents regarding running their binaries
				/ 	%li April 2, 2018: Grand Challenge acceptance notification
				/ 	%li April 13, 2018: Grand Challenge camera-ready paper submission
				/ 	%li April 30, 2018: Submission of corrected binaries
				%h4{class: 'specsess-heading'} Website
				TBA
				%h4{class: 'specsess-heading'} Organizers
				= render 'chairs', target: :gc_dlfr

	%div{class: 'panel panel-primary'}
		%div{class: 'panel-heading'}
			%h4{class: 'panel-title'}
				%a{'data-toggle': 'collapse', 'data-parent': '#accordion', href: '#gc-dash'}
					Grand Challenge on DASH
				%span{class: 'glyphicon glyphicon-link pull-right clickable-workshop-link', ldata: 'gc-dash'}
		%div{id: 'gc-dash', class: 'panel-collapse collapse'}
			%div{class: 'panel-body'}
				%h4{class: 'specsess-heading'} Description
				%p The MPEG DASH standard provides an interoperable representation format but deliberately does not define the adaptation behavior for the client implementations. In a typical deployment, the encoding is optimized for the respective delivery channels, but various issues during streaming (e.g., high startup delay, stalls/re-buffering, high switching frequency, inefficient network utilization, unfairness to competing network traffic, etc.) may limit the viewer experience.

				%p The goal of this grand challenge is to solicit contributions addressing end-to- end delivery aspects that will help improve the QoE while optimally using the network resources at an acceptable cost. Such aspects include, but are not limited to, content preparation for adaptive streaming, delivery in the Internet and streaming client implementations.

				%p A special focus of 2018’s grand challenge will be related to immersive media applications and services including omnidirectional/360-degree videos.
				%h4{class: 'specsess-heading'} Website
				%a{href: 'https://github.com/Dash-Industry-Forum/Academic-Track/wiki/DASH-Grand-Challenge-at-IEEE-ICME-2018'} https://github.com/Dash-Industry-Forum/Academic-Track/wiki/DASH-Grand-Challenge-at-IEEE-ICME-2018
				%h4{class: 'specsess-heading'} Organizers
				= render 'chairs', target: :gc_dash

	%div{class: 'panel panel-primary'}
		%div{class: 'panel-heading'}
			%h4{class: 'panel-title'}
				%a{'data-toggle': 'collapse', 'data-parent': '#accordion', href: '#gc-salient'}
					Salient360! 2018: Visual attention modeling for 360 Images - 2018 edition
				%span{class: 'glyphicon glyphicon-link pull-right clickable-workshop-link', ldata: 'gc-salient'}
		%div{id: 'gc-salient', class: 'panel-collapse collapse'}
			%div{class: 'panel-body'}
				%h4{class: 'specsess-heading'} Description
				%p Salient360! 2018 is the follow up of ICME 2017 Salient360! Grand challenge. With more than 30 submitted models, the first edition set the baseline for several types of visual attention models for 360 contents (saliency models, importance models, saccadic models) and ad hoc methodologies and ground- truth data to test each type of models.

				%p With this second edition, it is expected 1) to consolidate and improve the modeling of the first edition, 2) to extend the type of models (introducing head scan path model), and 3) to extend the type of input contents (introducing video).

				%p 2018 edition will also consider video content: Proponent/participants may propose models for either images and/or video. LF reconstruction from decimated-parallax imagery, i.e. from a given sparse set of camera images.
				%h4{class: 'specsess-heading'} Important Dates
				/ %ul
				/ 	%li March 1, 2018: Grand Challenge Winner Paper submission
				/ 	%li March 31, 2018: Grand Challenge Acceptance notification
				/ 	%li April 13, 2018: Grand Challenge Camera Ready Paper submission
				%h4{class: 'specsess-heading'} Website
				TBA
				%h4{class: 'specsess-heading'} Organizers
				= render 'chairs', target: :gc_salient

= render 'deadline', target: [:grand_challenge_suggested_winner_paper, :grand_challenge_suggested_acceptance, :grand_challenge_suggested_camera_ready_paper]

:javascript
	layout_helper.activate_hotlinked();