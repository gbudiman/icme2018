
%h1 Special Sessions

%div{class: 'panel-group', id: 'accordion'}
	%div{class: 'panel panel-primary'}
		%div{class: 'panel-heading'}
			%h4{class: 'panel-title'}
				%a{'data-toggle': 'collapse', 'data-parent': '#accordion', href: '#collapse-1'}
					Big Data Analytics: from Social Media to Physical Media
		%div{id: 'collapse-1', class: 'panel-collapse collapse'}
			%div{class: 'panel-body'}
				%h4{class: 'specsess-heading'} Aims and Scope
				%p We have witnessed the growing popularity of social networking services, such as FaceBook and Twitter based on structured text data, not to mention the even faster growing use of services based on unstructured media data, such as Periscope and Instagram, etc. Efficient analyses of the big mass of readily existing data from social media have created new opportunities to understand and predict the thoughts and behaviors of users. Many big data tools and applications are called for to meet such a high demand of data collections, such as Cloudera Impala and Microsoft Polybase. In the meanwhile, more and more Internet of Things (IoTs, such as the static and moving cameras and sensors) are being deployed on the cyber-physical infrastructure, where media data of physical objects are seamlessly collected and integrated into an Internet-like system so as to enable the physical objects and cyber-agents to interact with each other. The physical media, most of them are unstructured data, pose even higher challenges to the machine learning and data science community. Since both domains of big data, social media and physical media, are internet accessible and possibly correlated, it is thus beneficial to allow either side of data analytics to help the other side for better information and knowledge extraction. More specifically, how to take advantage of social media data analytics to more effectively and reliably detect/track/identify objects/events from physical media, so as to better narrow down the objects/events of main interest. On the other hand, the data analytics of physical media can certainly complement the insufficient descriptions or inferences made only by the structured text data or photos. In this special session, we intend to bring together researchers from both sides, the social media data science and physical media data analytics, so that either side can share the state-of- the-art accomplishments and better understand the current advances of the other side and seek the strategies of working together for better integration of both sidesâ€™ technologies, resulting in much more effective big data analytics systems.

				%h4{class: 'specsess-heading'} Topics
				%p 
					In this special session, we are soliciting original contributions on all aspects of the social media and physical media integration techniques, including but not limited to: 
					%ul
						%li Data analytics from surveillance camera arrays
						%li Data analytics from on-road dash cameras and car IoT sensors
						%li Social-guided multimedia representation learning
						%li Cross-media information indexing and retrieving
						%li User behaviors understanding from social and physical media
						%li User portrait from social and physical media
						%li Interpreting geographical and temporal contexts from social and physical media
						%li Object Re-ID from social and physical media
						%li Multimedia applications and services from social and physical media

				%h4{class: 'specsess-heading'} Special Session Chair
				= render 'chairs', target: :specsess_bda

	%div{class: 'panel panel-primary'}
		%div{class: 'panel-heading'}
			%h4{class: 'panel-title'}
				%a{'data-toggle': 'collapse', 'data-parent': '#accordion', href: '#collapse-5'}
					Learning-based Optimization for Multimedia Networking
		%div{id: 'collapse-5', class: 'panel-collapse collapse'}
			%div{class: 'panel-body'}
				%h4{class: 'specsess-heading'} Aims and Scope
				%p Recent multimedia networking has been shaped and will continue to be guided by distinguishing characteristics of multimedia applications and underlying infrastructures. First, in addition to the traditional audio and video, multimedia applications have begun to fuse with other applications, and penetrate into our daily life. One example is the social networking enabled multimedia applications. Driven by the sensor-rich mobile devices, the success of social networks, such as Facebook, Twitter, and Instagram, boosts the proliferation of community-shared multimedia. Meanwhile, new forms of multimedia data, such as geo-tagged information, 3D video, and VR/AR, have emerged in many applications. Second, novel networking infrastructures bring unpredictability in both breadth and depth, as well as great opportunities. The wide adoption of virtualization and cloud computing delegates more intelligence to the end nodes. The networking management and control become flexible and stochastics. In parallel, the underlying networking enables a huge transformation by new architecture, including software-defined networking (SDN), network function virtualization (NFV), edge cloud and fog. This enhances network automation in agile infrastructures.

				%p The existing research approaches are inadequate to support this accelerated and unpredictable growth in multimedia networking. Prevailing approaches typically assume some static or dynamics models for the system, and then develop algorithms and technologies via simulation platforms or small-scale systems. They cannot tackle the performance degradation caused by system unpredictability and model bias. Fortunately, the learning-based approach can endow multimedia systems some levels of self or reinforcement learning capabilities in response to fast-changing environments, and now is possible for researchers, owning to two technological trends. First, the emerging big data paradigm has rendered it easier for researchers to acquire, store, and analyze large datasets. For instance, Facebook and Twitter both release large-scale datasets and open APIs for researchers to crawl and analyze human behavior and information dissemination patterns. There are also some open-source projects and tools for big data analytics, such as Hadoop, Spark and GraphLab. Second, recent progresses on machine learning, especially deep learning and reinforcement learning, open an exciting new era of knowledge-based multimedia networking. For example, convolutional neural networks have demonstrated high capability in image recognition and language translation, deep reinforcement learning based robots outperform human beings in Go and e-sports.

				%p In this special session, we aim to call for a coordinated effort to understand the scenarios and challenges emerging in learning based multimedia networking, showcase innovative methodologies and ideas, as well as introduce large scale real systems or applications.

				%h4{class: 'specsess-heading'} Topics
				%p 
					In this special session, we are soliciting original contributions on all aspects of the social media and physical media integration techniques, including but not limited to: 
					%ul
						%li Learning based automated and closed-loop multimedia networking optimization
						%li Self-Learning for adaptive multimedia networking protocols and algorithms
						%li Resource allocation for multimedia applications using machine learning
						%li Deep learning and reinforcement learning in multimedia networking control and management
						%li Predictive-aware multimedia networking maintenance and optimization
						%li Deep learning based multimedia distribution and transmission
						%li Proactive multimedia network monitoring for security and diagnosis
						%li User experience-driven virtual or augmented reality (VR/AR) applications
						%li Real-time methods and applications for multimedia applications, such as cloud gaming and remote surgery

				%h4{class: 'specsess-heading'} Special Session Chair
				= render 'chairs', target: :specsess_lbo

	%div{class: 'panel panel-primary'}
		%div{class: 'panel-heading'}
			%h4{class: 'panel-title'}
				%a{'data-toggle': 'collapse', 'data-parent': '#accordion', href: '#collapse-6'}
					Deep Metric Learning for Multimedia Computing
		%div{id: 'collapse-6', class: 'panel-collapse collapse'}
			%div{class: 'panel-body'}
				%h4{class: 'specsess-heading'} Aims and Scope
				%p Similarity learning techniques have played a central role in multimedia computing, and a variety of distance metric learning methods have been developed for various multimedia applications over the past decade. Among these learning methods, deep metric learning approaches have achieved many state-of- the-art, which aims to learn an appropriate nonlinear distance functions given some constrains between samples. While these methods are helpful to learn the similarity of data such as images, videos, texts, radars, and voices, how to develop task-specific deep metric learning algorithms for different multimedia tasks still remains challenging, especially for big data which are captured in the wild. Moreover, how to develop transferable deep metric learning methods for large-scale multimedia systems still requires many efforts.

				%p This special issue serves as a forum for researchers all over the world to discuss their works and recent advances in deep metric learning for multimedia computing. Both state-of- the-art works on theories and applications of deep metric learning are welcome for submission.

				%h4{class: 'specsess-heading'} Topics
				%p 
					Topics of particular interest include, but are not limited to:
					%ul
						%li Semi-supervised deep metric learning for multimedia computing
						%li Multi-view deep metric learning for multimedia computing
						%li Structural deep metric learning for multimedia computing
						%li Domain transfer deep metric learning for multimedia computing
						%li Hashing-based deep metric learning for multimedia computing
						%li Large-scale deep metric learning for pattern recognition
						%li Comparative study of deep metric learning for multimedia computing

				%h4{class: 'specsess-heading'} Special Session Chair
				= render 'chairs', target: :specsess_dml

	%div{class: 'panel panel-primary'}
		%div{class: 'panel-heading'}
			%h4{class: 'panel-title'}
				%a{'data-toggle': 'collapse', 'data-parent': '#accordion', href: '#collapse-4'}
					Point Cloud Compression
		%div{id: 'collapse-4', class: 'panel-collapse collapse'}
			%div{class: 'panel-body'}
				%h4{class: 'specsess-heading'} Aims and Scope
				%p Point cloud capture and compression is becoming a key enabling technology for content capture for immersive visual experiences, cultural heritage preservation, smart city and auto driving/navigations, etc. The underlying challenges on geometrical and graph signal processing, have sparked active research efforts on new insight and new tools for graph/geometrical signal representation, sampling, filtering, transform and compression. On the MPEG side, a new call for proposal was issued for standardization of the point cloud compression technology. 

				%p In this special session, we will invite leading researchers in this topic area to contribute latest research results, reflecting the new state of art in point cloud compression technology and applications.

				%h4{class: 'specsess-heading'} Topics
				%p 
					Topics of particular interest include, but are not limited to:
					%ul
						%li Point cloud capture and processing
						%li Point cloud geometry compression
						%li Dynamic point cloud geometry modeling and compression
						%li Graph signal processing in point cloud compression
						%li Video based point cloud geometry compression
						%li Point cloud distortion and QoE metrics

				%h4{class: 'specsess-heading'} Special Session Chair
				= render 'chairs', target: :specsess_pcc

	%div{class: 'panel panel-primary'}
		%div{class: 'panel-heading'}
			%h4{class: 'panel-title'}
				%a{'data-toggle': 'collapse', 'data-parent': '#accordion', href: '#collapse-3'}
					Human Activity Analytics: Benchmark, Algorithms, and Applications
		%div{id: 'collapse-3', class: 'panel-collapse collapse'}
			%div{class: 'panel-body'}
				%h4{class: 'specsess-heading'} Aims and Scope
				%p Human activity analytics has been attracting an increasing attention. As a significant part of video understanding in the field of computer vision and multimedia, activity analytics such as Action Recognition and Action Detection remains a challenging problem. The technology will potentially facilitate a wide range of practical applications, such as intelligent video surveillance, human-computer interaction, video summary and understanding.

				%p For human activity analysis, many great algorithms have been designed for RGB videos recorded by 2D cameras. Recently, with the prevalence of the affordable color-depth sensing cameras like Microsoft Kinect and pose estimation techniques, it is much easier and cheaper to obtain infrared data, depth maps and the 3D skeleton of human body. The access of multi modal data further boosts the research in general action analysis. Besides, many datasets have also been collected with benchmarks provided, to adapt more conceivable application scenarios.

				%h4{class: 'specsess-heading'} Topics
				%p 
					Topics of particular interest include, but are not limited to:
					%ul
						%li Action Recognition / Detection
						%li 3D Action Recognition / Detection
						%li Multi-Modal Action Recognition / Detection
						%li Zero-Shot Action Recognition
						%li Temporal Action Localization in Untrimmed Video
						%li Online Activity Prediction
						%li Benchmark Datasets Supporting Activity Analytics
						%li Home Surveillance, Action-Assisted Care, and Application Domains
						%li Collective Activity Recognition

				%h4{class: 'specsess-heading'} Special Session Chair
				= render 'chairs', target: :specsess_haa

	%div{class: 'panel panel-primary'}
		%div{class: 'panel-heading'}
			%h4{class: 'panel-title'}
				%a{'data-toggle': 'collapse', 'data-parent': '#accordion', href: '#collapse-2'}
					Multimedia Edge Computing
		%div{id: 'collapse-2', class: 'panel-collapse collapse'}
			%div{class: 'panel-body'}
				%h4{class: 'specsess-heading'} Aims and Scope
				%p Driven by the proliferation of mobile devices and the availability of dedicated mobile media creation applications, the mobile multimedia traffic surges and has grown into an unprecedented level, which poses challenges on the traditional cloud-based architecture. This situation is further aggravated by the emergence of Virtual Reality, Augmented Reality and wearable technology, which poses stringent requirements in terms of latency. Traditional approach is to offload such data processing to the cloud, with consequent high traffic volumes in the backbone network and possible data latency increases. To cope with the exponentially increasing volume of data and balance local computation versus remote offloading for mobile multimedia application and service, recently, multimedia computing at the edge is promising, which allows computation and services to be hosted at the edge leveraging the emerging network architecture such as 5G, ICN, and smart Wi-Fi routers equipped with the computing, storage and communication ability. Multimedia Edge Computing makes these edge resources feasible to collect and process information locally and communicate with the back-end server coordinately, increasing the edge responsibility and reducing the network latency and bandwidth consumption. We believe a full investigation on the multimedia edge computing will definitely benefit the end users and the service providers in many aspects, such as the improved quality-of-experience, the reduced communication cost.

				%p This special session aims at demonstrating how multimedia edge computing techniques has contributed and are contributing to multimedia applications and services. We are pleased to invite researches and practitioners from academia and industry to share their insights and cutting-edge results.

				%h4{class: 'specsess-heading'} Topics
				%p 
					Topics of particular interest include, but are not limited to:
					%ul
						%li Content-aware Multimedia Pre-fetching and Caching at the Edge
						%li Multimedia Fog Computing and Communication
						%li Distributed Multimedia Big Data Management and Analytics
						%li Learning Based Multimedia Processing at Mobile Device and Edge Network
						%li Crowdsourced Mobile Multimedia Sensing
						%li Multimodality-based Internet-of- things Applications
						%li Delay Sensitive Edge Computing for AR Applications
						%li Edge-assisted Social-aware Multimedia Content Sharing and Distribution
						%li Multimedia Service Migration and Resource Allocation at the Edge
						%li Privacy Reserved Mobile Multimedia Recognition and Classification
						%li Cloudlet for Multimedia Application

				%h4{class: 'specsess-heading'} Special Session Chair
				= render 'chairs', target: :specsess_mec

%h4{class: 'specsess-heading'} Submission Guideline
%p
	Special sessions are oral sessions, all submissions will go through a regular paper review process and the reviewing will be double blind. Authors are invited to submit a full paper (two-column format, 6 pages maximum). Only electronic submissions will be accepted. Please use 
	%a{href: 'https://cmt3.research.microsoft.com/User/Login?ReturnUrl=%2FICME2018'}this link 
	for submission and 
	%a{href: '/author_info'} this submission guidelines.

%h4{class: 'specsess-heading'} Important Dates
= render 'deadline', target: [:regular_abstract, :regular_paper, :camera_regular], override: ['Abstract', 'Full Paper', 'Camera-Ready Paper']

/ %li 
/ 	%strong Deep Metric Learning for Multimedia Computing
/ 	%p Organizers: Jiwen Lu, Xiuzhuang Zhou

/ %li 
/ 	%strong Artificial intelligence for Multimedia Networking and Systems
/ 	%p Organizers: Han Hu, Nikolaos Thomos, Kenji Kanai

/ %li 
/ 	%strong Point Cloud Compression
/ 	%p Organizers: Zhu Li, Euee S. Jang, Rufael Mekuria, Gary Li

/ %li 
/ 	%strong Human Activity Analytics: Benchmark, Algorithms, and Applications
/ 	%p Organizers: Jiaying Liu and Xiaoyan Sun

/ %li
/ 	%strong Multimedia Edge Computing
/ 	%p Organizers: Lifeng Sun, Jianwei Huang